{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":15444,"sourceType":"datasetVersion","datasetId":11102},{"sourceId":11019295,"sourceType":"datasetVersion","datasetId":6861420},{"sourceId":11032994,"sourceType":"datasetVersion","datasetId":6871679},{"sourceId":114227014,"sourceType":"kernelVersion"}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install required dependencies and import necessary libraries\n!pip install codecarbon #profiler\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\nimport pandas as pd\nimport os\nimport time\nfrom tqdm import tqdm\nfrom codecarbon import EmissionsTracker\n\n# Set device (Use GPU if available)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Hyperparameters\nEPOCHS = 20\nBATCH_SIZE = 64  # Reduce batch size to avoid memory issues\nLR = 0.01\nWEIGHT_DECAY = 5e-4\nMOMENTUM = 0.9\nNUM_CLASSES = 100  # CIFAR-100\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T09:36:26.101210Z","iopub.execute_input":"2025-03-20T09:36:26.101547Z","iopub.status.idle":"2025-03-20T09:36:36.823076Z","shell.execute_reply.started":"2025-03-20T09:36:26.101506Z","shell.execute_reply":"2025-03-20T09:36:36.822312Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: codecarbon in /usr/local/lib/python3.10/dist-packages (2.8.3)\nRequirement already satisfied: arrow in /usr/local/lib/python3.10/dist-packages (from codecarbon) (1.3.0)\nRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from codecarbon) (8.1.7)\nRequirement already satisfied: fief-client[cli] in /usr/local/lib/python3.10/dist-packages (from codecarbon) (0.20.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from codecarbon) (2.2.3)\nRequirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from codecarbon) (0.21.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from codecarbon) (5.9.5)\nRequirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from codecarbon) (9.0.0)\nRequirement already satisfied: pynvml in /usr/local/lib/python3.10/dist-packages (from codecarbon) (12.0.0)\nRequirement already satisfied: questionary in /usr/local/lib/python3.10/dist-packages (from codecarbon) (2.1.0)\nRequirement already satisfied: rapidfuzz in /usr/local/lib/python3.10/dist-packages (from codecarbon) (3.12.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from codecarbon) (2.32.3)\nRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from codecarbon) (13.9.4)\nRequirement already satisfied: typer in /usr/local/lib/python3.10/dist-packages (from codecarbon) (0.15.1)\nRequirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from arrow->codecarbon) (2.9.0.post0)\nRequirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.10/dist-packages (from arrow->codecarbon) (2.9.0.20241206)\nRequirement already satisfied: httpx<0.28.0,>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from fief-client[cli]->codecarbon) (0.27.2)\nRequirement already satisfied: jwcrypto<2.0.0,>=1.4 in /usr/local/lib/python3.10/dist-packages (from fief-client[cli]->codecarbon) (1.5.6)\nRequirement already satisfied: yaspin in /usr/local/lib/python3.10/dist-packages (from fief-client[cli]->codecarbon) (3.1.0)\nRequirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas->codecarbon) (1.26.4)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->codecarbon) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->codecarbon) (2025.1)\nRequirement already satisfied: nvidia-ml-py<13.0.0a0,>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from pynvml->codecarbon) (12.570.86)\nRequirement already satisfied: prompt_toolkit<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from questionary->codecarbon) (3.0.48)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->codecarbon) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->codecarbon) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->codecarbon) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->codecarbon) (2025.1.31)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->codecarbon) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->codecarbon) (2.19.1)\nRequirement already satisfied: typing-extensions<5.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from rich->codecarbon) (4.12.2)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer->codecarbon) (1.5.4)\nRequirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (3.7.1)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (1.0.7)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (1.3.1)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (0.14.0)\nRequirement already satisfied: cryptography>=3.4 in /usr/local/lib/python3.10/dist-packages (from jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (44.0.1)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->codecarbon) (0.1.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas->codecarbon) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas->codecarbon) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas->codecarbon) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas->codecarbon) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas->codecarbon) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas->codecarbon) (2.4.1)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt_toolkit<4.0,>=2.0->questionary->codecarbon) (0.2.13)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7.0->arrow->codecarbon) (1.17.0)\nRequirement already satisfied: termcolor<2.4.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from yaspin->fief-client[cli]->codecarbon) (2.3.0)\nRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=3.4->jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (1.17.1)\nRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (1.2.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.22.4->pandas->codecarbon) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.22.4->pandas->codecarbon) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.22.4->pandas->codecarbon) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.22.4->pandas->codecarbon) (2024.2.0)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=3.4->jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (2.22)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.22.4->pandas->codecarbon) (2024.2.0)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from torchvision.transforms import AutoAugment, AutoAugmentPolicy\n\n# Correct order: Apply AutoAugment before ToTensor()\ntransform_train = transforms.Compose([\n    transforms.RandomCrop(32, padding=4),\n    transforms.RandomHorizontalFlip(),\n    AutoAugment(AutoAugmentPolicy.CIFAR10),  # Must be applied before ToTensor()\n    transforms.ToTensor(),\n    transforms.Normalize((0.5071, 0.4865, 0.4409), (0.2673, 0.2564, 0.2762)),\n    transforms.RandomErasing(p=0.2)\n])\n\ntransform_test = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5071, 0.4865, 0.4409), (0.2673, 0.2564, 0.2762))\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T09:36:36.824446Z","iopub.execute_input":"2025-03-20T09:36:36.824944Z","iopub.status.idle":"2025-03-20T09:36:36.829851Z","shell.execute_reply.started":"2025-03-20T09:36:36.824915Z","shell.execute_reply":"2025-03-20T09:36:36.829125Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Load CIFAR-100 dataset and prepare dataloaders\n\ntrainset = torchvision.datasets.CIFAR100(root=\"./data\", train=True, download=True, transform=transform_train)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n\ntestset = torchvision.datasets.CIFAR100(root=\"./data\", train=False, download=True, transform=transform_test)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T09:36:36.831039Z","iopub.execute_input":"2025-03-20T09:36:36.831351Z","iopub.status.idle":"2025-03-20T09:36:43.038136Z","shell.execute_reply.started":"2025-03-20T09:36:36.831325Z","shell.execute_reply":"2025-03-20T09:36:43.037067Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 169M/169M [00:02<00:00, 69.2MB/s] \n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/cifar-100-python.tar.gz to ./data\nFiles already downloaded and verified\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Define ResNet model with Residual Blocks\nclass ResidualBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, stride=1):\n        super(ResidualBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        \n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_channels != out_channels:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(out_channels)\n            )\n\n    def forward(self, x):\n        out = torch.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += self.shortcut(x)\n        return torch.relu(out)\n\nclass ResNet(nn.Module):\n    def __init__(self, block, num_classes=100):\n        super(ResNet, self).__init__()\n        self.in_channels = 64\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.layer1 = self._make_layer(block, 64, 2, stride=1)\n        self.layer2 = self._make_layer(block, 128, 2, stride=2)\n        self.layer3 = self._make_layer(block, 256, 2, stride=2)\n        self.layer4 = self._make_layer(block, 512, 2, stride=2)\n        self.fc = nn.Linear(512, num_classes)\n\n    def _make_layer(self, block, out_channels, num_blocks, stride):\n        layers = []\n        for _ in range(num_blocks):\n            layers.append(block(self.in_channels, out_channels, stride))\n            self.in_channels = out_channels\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = torch.relu(self.bn1(self.conv1(x)))\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = torch.flatten(out, start_dim=1)\n        return self.fc(out)\n\n# Initialize Model\nmodel = ResNet(ResidualBlock, num_classes=NUM_CLASSES).to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T09:36:43.039287Z","iopub.execute_input":"2025-03-20T09:36:43.039639Z","iopub.status.idle":"2025-03-20T09:36:43.411486Z","shell.execute_reply.started":"2025-03-20T09:36:43.039597Z","shell.execute_reply":"2025-03-20T09:36:43.410781Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss(label_smoothing=0.1)  # Label smoothing for better generalization\noptimizer = optim.SGD(model.parameters(), lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\nscheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T09:36:43.412217Z","iopub.execute_input":"2025-03-20T09:36:43.412447Z","iopub.status.idle":"2025-03-20T09:36:43.417186Z","shell.execute_reply.started":"2025-03-20T09:36:43.412427Z","shell.execute_reply":"2025-03-20T09:36:43.416294Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"tracker = EmissionsTracker(log_level=\"critical\", output_file=\"emissions.csv\", output_dir=\"./\")\n\ndef train_and_evaluate():\n    best_acc = 0.0\n    total_start_time = time.time()\n    tracker.start()\n\n    for epoch in range(EPOCHS):\n        epoch_start_time = time.time()\n        model.train()\n        correct, total, running_loss = 0, 0, 0.0\n\n        progress_bar = tqdm(trainloader, desc=f\"Epoch {epoch+1}/{EPOCHS}\", unit=\"batch\")\n        for inputs, targets in progress_bar:\n            inputs, targets = inputs.to(device), targets.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, targets)\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n            _, predicted = outputs.max(1)\n            total += targets.size(0)\n            correct += predicted.eq(targets).sum().item()\n\n            progress_bar.set_postfix(loss=f\"{loss.item():.4f}\", acc=f\"{100. * correct / total:.2f}%\")\n\n        train_acc = 100. * correct / total\n        scheduler.step()\n        epoch_time = time.time() - epoch_start_time\n        print(f\"Epoch {epoch+1}: Train Acc: {train_acc:.2f}%, Time: {epoch_time:.2f}s\")\n\n    tracker.stop() # Stop emissions tracking and display total CO₂ emissions\n    total_time = time.time() - total_start_time\n    print(f\"Total Training Time: {total_time:.2f}s\")\n\ntrain_and_evaluate()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}